\documentclass[twoside,11pt]{article}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

\usepackage{jmlr2e}
\usepackage{caption}
\usepackage{subcaption}
%\usepackage{parskip}

% Definitions of handy macros can go here
\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}
% Heading arguments are {volume}{year}{pages}{submitted}{published}{author-full-names}

% Short headings should be running head and authors last names
\ShortHeadings{95-845: AAMLP Fina Paper}{Khin and Leahy}
\firstpageno{1}

\begin{document}

\title{Heinz 95-845: Predicting Influenza Infection Chances and Identifying Risk Factors}

\author{\name Kaung Khin \email kkhin/kkhin@andrew.cmu.edu \\
       \addr Heinz College\\
       Carnegie Mellon University\\
       Pittsburgh, PA, United States
       \AND
       \name Shawn Leahy \email sleahy/sleahy@andrew.cmu.edu \\
       \addr Heinz College\\
       Carnegie Mellon University\\
       Pittsburgh, PA, United States}

\maketitle

\begin{abstract}
Influenza is a highly contagious disease prone to cause epidemics around the world.  Predicting individuals with a high chance of infection and identifying the spread of the disease could allow health care systems to better optimize how resources are used to combat the spread.  Predicting outbreaks is a multidimensional problem involving many different fields.  In this paper we investigate how historical medical and demographic survey information combined with Internet search engine use can be used to predict the chance of infection for individuals in different regions of the United States.  We compare the effectiveness of the Random Forest Algorithm with Gradient Boosted Trees and evaluate using ROC curves and the AUC metric.    
\end{abstract}

\section{Introduction}
Influenza, or simply the flu, is a seasonal contagious respiratory disease that
affects millions of people in the United States yearly with outcomes ranging
from just mild symptoms to even death. \citep{cdc} It is caused by the influenza virus with the most infamous version in recent time being the 1918 flu pandemic nicknamed the Spanish Flu. \citep{rolfes_etal_2017} Although the disease is commonly self-limiting, it can progress to influenza pneumonia, which has a significant mortality. Up to 50,000 are killed each year by influenza-like illnesses.  Because influenza causes significant morbidity, can be fatal, and often presents with new strains, the prediction of vulnerable populations can be of value in allowing for timely preventive public health planning and interventions to be used to mitigate the effect of these outbreaks.     

The economic cost of the flu on the United States is estimated to be in the billions of dollars.  Questions such as which states or counties bear high costs and where to distribute vaccines to achieve the maximum returns are crucial to improving future effectiveness of the health care system.  

In 2008 Google explored flu forecasting in real time based on search histories.
Unfortunately, at the peak of the 2013 flu season, the predictions were off by
more than 140 percent. \citep{lazer_kennedy_king_vespignani_2014} The use of big
data to track flu trends is not a novel idea, in fact many studies have
attempted to learn from the mistakes of Google Flu Trends. The challenges of
using big data to attempt this type of prediction is well-documented.
\citep{lazer_kennedy_king_vespignani_2014} However, there has been some success in
the use of social media data and search data combined with health surveillance
data to track and predict the number of cases for the Zika virus outbreak in
Latin America. \citep{mcgough_brownstein_hawkins_santillana_2017} 

Here we demonstrate that the tracking of influenza search engine tracking
combined with demographic and medical data and a suitable machine learning
algorithm can accurately predict influenza infection probabilities \citep{ginsberg_2009} and assist in identifying at risk populations at the regional scale in the United States. 

\section{Methods}

\subsection*{Data}

We utilize survey data collected from the Medical Expenditure Panel Survey
(MEPS) from the Agency for Healthcare Research and Quality (AHRQ) a section of
the U.S. Department of Health and Human Services.  MEPS is a set of large-scale
surveys of families and individuals, their medical providers (doctors,
hospitals, pharmacies, etc.), and employers across the United States. The
Household Component collects data from a sample of families and individuals in
selected communities across the United States, drawn from a nationally
representative subsample.  The Medical Conditions file provides information on
household-reported medical conditions.  The Prescribed Medicines file contains
household-reported prescribed medicine that was purchased during calendar year. \citep{meps} 

\begin{table}[h]
\centering
\caption{Unique Individuals in Each Survey Year}
\begin{tabular}{ll}
\hline
Year & Sample Size\\ \hline
2015 & 35,427\\
2014 & 34,875\\
2013 & 36,940\\
2012 & 38,974\\
\end{tabular}
\end{table}

Google trends is a public we API based on the Google search engine that shows how often a particular search-term is entered relative to the total search-volume around the world.  The search trends can be filtered by country, state, category, web search/image search/news search, and time. Here we include the following terms: "influenza", "flu", "flu symptoms", "flu treatments", and "flu remedies".

We limit the search results to occur in 2012, 2013, 2014, and 2015 separately.  We limit it to include the United States on the state level.  Values are calculated on a scale from 0 to 100, where 100 is the location with the most popularity as a fraction of total searches in that location, a value of 50 indicates a location which is half as popular. A value of 0 indicates a location where there was not enough data for this term.  A higher value means a higher proportion of all queries, not a higher absolute query count. So a tiny state where 80\% of the queries are for "bananas" will get twice the score of a giant country where only 40\% of the queries are for "bananas".  These results are aggregated from states to U.S. Census regions in order to match up with the granularity of the MEPS data.

\subsection{Data Cleaning and Feature Engineering}

Survey data provides several layers of difficulty in order to transform it into a consistent and usable form. MEPS is a comprehensive survey, and in the 2015 Household data file along there are 1,832 features.  The first step is to filter out many of these columns in the Household file, Medical Conditions file, and Prescribed Medicines file for each year. In the Household data we perform one-hot-encoding on the categorical variables we kept in the previous stage.  For the Medical Conditions and Prescribed Medicines files we aggregate them up from the condition and prescription level to the individual level.  In the Medical Conditions file we obtain counts of inpatient visits, outpatient visits, office based visits, emergency room visits, and number of prescriptions for each individual.  We also create a flag indicator using ICD-9 codes if an individual had influenza.  In the Prescribed medicines file we use National Drug Codes (NDC) in order to identify individuals who were prescribed Tamiflu, the only unique influenza treatment present in the dataset.  

Due to the nature of conducting a survey, there are several variable values reserved for circumstances that can arise while the survey is being conducted.  These values are found in Table \ref{reserved_vals}.

\begin{table}[h]
\centering
\caption{Reserved Value Codes in MEPS Data Files}
\label{reserved_vals}
\begin{tabular}{cl}
\hline
Value & Definition\\ \hline
-1 & Question was not asked due to skipped pattern\\
-2 & Not asked because there was no change since previous round \\
-7 & Question was asked and respondent refused to answer question\\
-8 & Question was asked and respondent did not know answer\\
-9 & Interviewer did not record the data\\
\end{tabular}
\end{table}

These values can occur in almost any variable field regardless of variable type.  Some of these values are not missing at random and as such we cannot conduct imputation methods. For reserved value code -9 (Interviewer did not record the data) and -8 (Question was asked and respondent did not know answer), these values are missing at random and so we perform value imputations for this value.  For binary value columns we impute the most frequent value, and for numerical columns we impute the mean. This comes out to about 8,000 imputations over all features for all years.  

\subsection{Data Exploration}

After cleaning the data and performing the above feature engineering, we end up with the count of influenza cases by year is presented in Table \ref{flu_counts}.  We note the higher total frequencies in 2012 and 2013 are consistent with reporting by the Center for Disease Control (CDC) which states, "the 2012-2013 season was moderately severe, with a high percentage of outpatient visits for influenza-like illness, high rates of hospitalization, and more reported deaths attributed to pneumonia and influenza compared with recent years.(1)"  In comparison the 2014-2015 flu season according to the CDC began later than normal and as such some counts for those years are are lower.

\begin{table}[h]
\centering
\caption{Influenza Occurrence in Data}
\label{flu_counts}
\begin{tabular}{cccc}
\hline
Year & Total Influenza Cases & Influenza with Tamiflu & Tamiflu without Influenza\\ \hline
2015 & 1,697 & 153 & 28\\
2014 & 1,803 & 197 & 38\\
2013 & 3,214 & 154 & 23\\
2012 & 3,111 & 86 & 25\\
\end{tabular}
\end{table}

Table \ref{flu_counts} also contains counts of individuals with the flu and Tamiflu and without the flu but having been prescribed Tamiflu.  We observe that even in severe flu seasons, Tamiflu prescriptions only make up a small percentage of total cases (5\%-10\%).  We also observe less than 100 cases where an individual was prescribed Tamiflu, but did not have a flu diagnosis.  This result is not surprising when dealing with survey data.  If the data had been vetted by hospital and prescription records, we could justify imputation of the flu, however the survey data is based on an individuals answer to a questionnaire. We posit that these cases are mistakes either from the transcriber or from the individuals answering the questions.  

\begin{figure}[h]
\centering
\begin{subfigure}{.4\textwidth}
  \centering
  \includegraphics[width=\linewidth]{pop_by_region}
  \caption{Histogram of Population by Region for Each Year}
  \label{fig:hist_by_region}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{fam_inc_by_pop}
  \caption{Histogram of Family Income by Year}
  \label{fig:hist_by_inc}
\end{subfigure}
\caption{Histograms Describing the Data}
\label{fig:data_desc}
\end{figure}

Figure \ref{fig:data_desc} illustrates some of the demographics of the data from the MEPS dataset for each of the years under observation.  We observe consistency in demographics across the years 2012-2015.  Figure \ref{fig:hist_by_region} describes how much of each sample comes from each Census region in the country.  We observe the majority of the sample comes from the South and West portions of the United States.  This is fairly consistent with the distribution of population according to the U.S. Census.  Figure \ref{fig:hist_by_inc} describes a histogram of family income for each of the sample years.  This again follows the U.S. Census distribution with approximately 20\% below \$20,000 and around 50\% below \$100,000 in family income.     

\begin{table}[h]
\centering
\caption{Relative Proportion of Search Results for Flu Related Terms by Region}
\label{flu_prop}
\begin{tabular}{lcccc}
\hline
Year & Northeast & Midwest & South & West\\ \hline
2015 & 51\% & 63\% & 53\% & 50\%\\
2014 & 70\% & 85\% & 80\% & 70\%\\
2013 & 77\% & 82\% & 79\% & 71\%\\
2012 & 50\% & 76\% & 71\% & 65\%\\
\end{tabular}
\end{table}

As stated above, we aggregate the Google search data proportions up from the state level to the Census region level by averaging the values for the states in each region.  Table \ref{flu_prop} shows these values for each region for each year.  We can see that the Midwest has a particularly high proportion of all cases over all the years.

\section{Initial Modeling and Improving the Model}
\subsection*{Baseline Model-Random Forest}

We began by concatenating the the 2012-14 data into a training set and testing on the 2015 data.  We use our created "flu-flag" from the medical conditions file as our target variable.  We run a Random Forest classification model using entropy as our splitting criteria and allowing all trees to grow to their maximum depth.  Figure \ref{fig:initial_roc} shows the results in a ROC curve with an AUC score of 0.54.  Figure\ref{fig:initial_varimport} shows the variable importance for the initial Random Forest Model.  Some of the top variables include: Percentage of the federal poverty level individual resides at, family income, age, BMI, number of office based visits to a health provider, number of prescription drugs used, proportion of Internet searches for flu terms in their region, whether the individual received Tamiflu, and whether the individual received a flu shot.  This model does not do much better than flipping a coin so we will utilize other methods to obtain a better predictive outcome.   

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{initial_rf}
  \caption{ROC Curve with AUC}
  \label{fig:initial_roc}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{initial_rf_varimport}
  \caption{Random Forest Variable Importance}
  \label{fig:initial_varimport}
\end{subfigure}
\caption{Results from Initial Random Forest Model}
\label{fig:initial_results}
\end{figure}

\subsection*{Balancing the dataset}

As our initial modeling show that we are barely doing better than random, we
note that the data imbalance is significant in our data set. We can see from
Table \ref{data_balancing}, our original data only contains 8128 cases of flu.
We investigated a few techniques for balancing the data set with synthetic data for the
under-represented class and up sampling the minority class.\citep{SMOTE, ADASYN}  The use of SMOTE and
ADASYN for data imbalance issues has been well documented \citep{Blagus2013}. We
can now see from Table \ref{data_balancing} that in both ADASYN and SMOTE
methods, the classes are now completely balanced. It is important to note that
the new synthetic data is generated using a nearest neighbor approach of the
feature space so the synthetic data is not completely at random. \citep{SMOTE} 

\begin{table}[h]
\centering
\caption{Data Balancing By Different Methods}
\label{data_balancing}
\begin{tabular}{ccc}
\hline
  Method & Records Without Flu & Records With Flu\\ \hline
  Normal Dataset & 102661 & 8128\\
  Upsampling & 102661 & 20000\\
  SMOTE & 102661 & 102661\\
  ADASYN & 102661 & 102661\\
\end{tabular}
\end{table}

\subsection*{Choosing the right metric}
Since we are using a held out test set to evaluate the performance of our
models and not generating synthetic data for the test set, we still face the
problem of data imbalance in test data set. In optimizing our machine learning
models by grid searching for the best hyper parameters, we used F-1 score as the
evaluation metric as it takes into account both the precision and recall of the
model while also weighting them. This metric is more suitable for our data
imbalance case because if we use a metric such as precision, the metric can be
easily skewed by the majority class.

\section{Results} 
With the balanced data set, we set out to improve the AUC ROC of our initial
models. We tested a variety of machine learning models including $l_2$
regularized logistic regression, random forests, gradient boosted forests,
support vector machines and neural networks. We have chosen not to include run
the models on ADASYN dataset in the interest of time as grid searching
hyper-parameters while also performing cross validation took a lot of time. We
mitigated some of the time required by random searching instead of grid
searching as this has been proven to be equally as good if not better. 
We used an instance of Amazon Web Service's C5 9X Large for models that uses the
CPU while our neural network models were run on a NVIDIA GTX 1080Ti using the Keras
library with a Tensorflow backend.
\subsection*{Model Comparison}

Table \ref{model_results} shows the AUC for the different models that we ran with
each algorithm being run on the normal dataset, upsampled dataset and the SMOTE
dataset. We can see from the table that random forests performed the best
overall while SVMs did considerably worse with the highest AUC barely better
than random at 0.51. It is clear that in all of the machine learning algorithms,
except neural networks, either the upsampled dataset or the SMOTE dataset
performs considerably better than the original dataset. We note that the highest
improvement we had was for random forests with the SMOTE dataset at 0.69. This
yielded an improvement gain of over 27\% from our baseline model.

\begin{table}[h]
\centering
\caption{Model Comparison}
\label{model_results}
\begin{tabular}{|c||c|c|c|}
  \hline
  \multicolumn{4}{|c|}{Area Under Curve - ROC} \\
  \hline
  & Normal Dataset& Upsampled Dataset & SMOTE Dataset \\
  \hline
  Random Forests  & 0.54 & 0.68 & \textbf{0.69} \\
  Gradient Boosted Trees   & 0.50 & \textbf{0.58} & 0.54 \\
  $l_2$ Logistic Regression  & 0.50 & 0.52 & \textbf{0.56} \\
  Neural Networks & \textbf{0.55} & 0.50 & 0.54\\
  Support Vector Machines & 0.50 & 0.50 & \textbf{0.51} \\
  \hline
\end{tabular}
\end{table}
\subsection*{Model Ensembling}
While several models, notably random forests, performed well after the balancing
of the dataset, we noticed that models such as SVMs and logistic regression
performed better in terms of reducing the number of false positives. However,
the models did worse overall in terms of AUC score. Given these different
models in prediction power of different classes, we created an ensemble of
models using a weighted approach. Ensembling models is not a novel idea in
machine learning and the benefit of ensembling models has been well
studied.  In fact, ensemble methods are currently dominate in most Kaggle
competitions in terms of prediction power.

\begin{table}[h]
\centering
\caption{Ensemble Model Performance}
\label{ensembleModel}
\begin{tabular}{ccc}
\hline
   & AUC ROC & Weights\\ \hline
  Normal Dataset & 102661 & 8128\\
\end{tabular}
\end{table}
\section{Discussion and Conclusion} 

\bibliography{FinalPaper}
\end{document} 